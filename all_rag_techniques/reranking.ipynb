{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reranking Methods in RAG Systems\n",
        "\n",
        "## Overview\n",
        "Reranking is a crucial step in Retrieval-Augmented Generation (RAG) systems that aims to improve the relevance and quality of retrieved documents. It involves reassessing and reordering initially retrieved documents to ensure that the most pertinent information is prioritized for subsequent processing or presentation.\n",
        "\n",
        "## Motivation\n",
        "The primary motivation for reranking in RAG systems is to overcome limitations of initial retrieval methods, which often rely on simpler similarity metrics. Reranking allows for more sophisticated relevance assessment, taking into account nuanced relationships between queries and documents that might be missed by traditional retrieval techniques. This process aims to enhance the overall performance of RAG systems by ensuring that the most relevant information is used in the generation phase.\n",
        "\n",
        "## Key Components\n",
        "Reranking systems typically include the following components:\n",
        "\n",
        "1. Initial Retriever: Often a vector store using embedding-based similarity search.\n",
        "2. Reranking Model: This can be either:\n",
        "   - A Large Language Model (LLM) for scoring relevance\n",
        "   - A Cross-Encoder model specifically trained for relevance assessment\n",
        "3. Scoring Mechanism: A method to assign relevance scores to documents\n",
        "4. Sorting and Selection Logic: To reorder documents based on new scores\n",
        "\n",
        "## Method Details\n",
        "The reranking process generally follows these steps:\n",
        "\n",
        "1. Initial Retrieval: Fetch an initial set of potentially relevant documents.\n",
        "2. Pair Creation: Form query-document pairs for each retrieved document.\n",
        "3. Scoring: \n",
        "   - LLM Method: Use prompts to ask the LLM to rate document relevance.\n",
        "   - Cross-Encoder Method: Feed query-document pairs directly into the model.\n",
        "4. Score Interpretation: Parse and normalize the relevance scores.\n",
        "5. Reordering: Sort documents based on their new relevance scores.\n",
        "6. Selection: Choose the top K documents from the reordered list.\n",
        "\n",
        "## Benefits of this Approach\n",
        "Reranking offers several advantages:\n",
        "\n",
        "1. Improved Relevance: By using more sophisticated models, reranking can capture subtle relevance factors.\n",
        "2. Flexibility: Different reranking methods can be applied based on specific needs and resources.\n",
        "3. Enhanced Context Quality: Providing more relevant documents to the RAG system improves the quality of generated responses.\n",
        "4. Reduced Noise: Reranking helps filter out less relevant information, focusing on the most pertinent content.\n",
        "\n",
        "## Conclusion\n",
        "Reranking is a powerful technique in RAG systems that significantly enhances the quality of retrieved information. Whether using LLM-based scoring or specialized Cross-Encoder models, reranking allows for more nuanced and accurate assessment of document relevance. This improved relevance translates directly to better performance in downstream tasks, making reranking an essential component in advanced RAG implementations.\n",
        "\n",
        "The choice between LLM-based and Cross-Encoder reranking methods depends on factors such as required accuracy, available computational resources, and specific application needs. Both approaches offer substantial improvements over basic retrieval methods and contribute to the overall effectiveness of RAG systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "\n",
        "<img src=\"../images/reranking-visualization.svg\" alt=\"rerank llm\" style=\"width:100%; height:auto;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "\n",
        "<img src=\"../images/reranking_comparison.svg\" alt=\"rerank llm\" style=\"width:100%; height:auto;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Package Installation and Imports\n",
        "\n",
        "The cell below installs all necessary packages required to run this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added project root to path: /Users/ruhwang/Desktop/AI/my_projects/context-engineering/advanced-rag\n",
            "✅ Package imported successfully!\n",
            "LANGCHAIN_API_KEY not set (empty in .env file)\n",
            "Environment setup complete!\n",
            "=== API Keys from config.py ===\n",
            "  GROQ_API_KEY: Loaded\n",
            "  COHERE_API_KEY: Loaded\n",
            "  OPENAI_API_KEY: Loaded\n",
            "  LANGCHAIN_API_KEY: Missing\n",
            "\n",
            "=== Environment Variables ===\n",
            "  os.environ['GROQ_API_KEY']: Set\n",
            "  os.environ['COHERE_API_KEY']: Set\n",
            "\n",
            "All essential keys loaded!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Define the directory *containing* the all_rag_techniques package\n",
        "# Get the directory of the current notebook/script (__file__ might not work in some notebooks)\n",
        "# Assuming the notebook is inside all_rag_techniques/\n",
        "current_dir = Path.cwd() \n",
        "\n",
        "# The directory containing 'all_rag_techniques' is the parent directory\n",
        "project_root = current_dir.parent \n",
        "\n",
        "# 2. Add this root to the system path\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "    print(f\"Added project root to path: {project_root}\")\n",
        "else:\n",
        "    print(\"Project root already in path.\")\n",
        "\n",
        "# 3. Now the import should work\n",
        "try:\n",
        "    from all_rag_techniques import setup_environment, check_keys\n",
        "    print(\"✅ Package imported successfully!\")\n",
        "    setup_environment()\n",
        "    check_keys()\n",
        "except Exception as e:\n",
        "    print(f\"❌ Final import failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "from langchain.docstore.document import Document\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "# Original path append replaced for Colab compatibility\n",
        "from helper_functions import *\n",
        "from evaluation.evalute_rag import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the document's path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"/Users/ruhwang/Desktop/AI/my_projects/context-engineering/advanced-rag/data/Understanding_Climate_Change.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorstore = encode_pdf(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 1: LLM based function to rerank the retrieved documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "\n",
        "<img src=\"../images/rerank_llm.svg\" alt=\"rerank llm\" style=\"width:40%; height:auto;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a custom reranking function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RatingScore(BaseModel):\n",
        "    relevance_score: float = Field(..., description=\"The relevance score of a document to a query.\")\n",
        "\n",
        "def rerank_documents(query: str, docs: List[Document], top_n: int = 3) -> List[Document]:\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"query\", \"doc\"],\n",
        "        template=\"\"\"On a scale of 1-10, rate the relevance of the following document to the query. Consider the specific context and intent of the query, not just keyword matches.\n",
        "        Query: {query}\n",
        "        Document: {doc}\n",
        "        Relevance Score:\"\"\"\n",
        "    )\n",
        "    \n",
        "    llm = ChatOpenAI(temperature=0.5, model_name=\"gpt-4o-mini\", max_tokens=4000)\n",
        "    llm_chain = prompt_template | llm.with_structured_output(RatingScore)\n",
        "    \n",
        "    scored_docs = []\n",
        "    for doc in docs:\n",
        "        input_data = {\"query\": query, \"doc\": doc.page_content}\n",
        "        score = llm_chain.invoke(input_data).relevance_score\n",
        "        try:\n",
        "            score = float(score)\n",
        "        except ValueError:\n",
        "            score = 0  # Default score if parsing fails\n",
        "        scored_docs.append((doc, score))\n",
        "    \n",
        "    reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
        "    return [doc for doc, _ in reranked_docs[:top_n]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example usage of the reranking function with a sample query relevant to the document\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top initial documents:\n",
            "\n",
            "Document 1:\n",
            "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
            "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
            "experiencing shi...\n",
            "\n",
            "Document 2:\n",
            "goals. Policies should promote synergies between biodiversity conservation and climate \n",
            "action. \n",
            "Chapter 10: Climate Change and Human Health \n",
            "Health Impacts \n",
            "Heat-Related Illnesses \n",
            "Rising temperature...\n",
            "\n",
            "Document 3:\n",
            "managed retreats. \n",
            "Extreme Weather Events \n",
            "Climate change is linked to an increase in the frequency and severity of extreme weather \n",
            "events, such as hurricanes, heatwaves, droughts, and heavy rainfall...\n",
            "Query: What are the impacts of climate change on biodiversity?\n",
            "\n",
            "Top reranked documents:\n",
            "\n",
            "Document 1:\n",
            "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
            "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
            "experiencing shi...\n",
            "\n",
            "Document 2:\n",
            "protection, and habitat creation. \n",
            "Climate-Resilient Conservation \n",
            "Conservation strategies must account for climate change impacts to be effective. This \n",
            "includes identifying climate refugia, areas le...\n",
            "\n",
            "Document 3:\n",
            "Coral reefs are highly sensitive to changes in temperature and acidity. Ocean acidification \n",
            "and warming waters contribute to coral bleaching and mortality, threatening biodiversity and \n",
            "fisheries. Pr...\n"
          ]
        }
      ],
      "source": [
        "query = \"What are the impacts of climate change on biodiversity?\"\n",
        "initial_docs = vectorstore.similarity_search(query, k=15)\n",
        "reranked_docs = rerank_documents(query, initial_docs)\n",
        "\n",
        "# print first 3 initial documents\n",
        "print(\"Top initial documents:\")\n",
        "for i, doc in enumerate(initial_docs[:3]):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document\n",
        "\n",
        "# Print results\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(\"Top reranked documents:\")\n",
        "for i, doc in enumerate(reranked_docs):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a custom retriever based on our reranker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/rt/0kf7v29569z7rctzmpst_dsh0000gn/T/ipykernel_58183/1141410002.py:2: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  class CustomRetriever(BaseRetriever, BaseModel):\n",
            "/var/folders/rt/0kf7v29569z7rctzmpst_dsh0000gn/T/ipykernel_58183/1141410002.py:2: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
            "  class CustomRetriever(BaseRetriever, BaseModel):\n"
          ]
        }
      ],
      "source": [
        "# Create a custom retriever class\n",
        "class CustomRetriever(BaseRetriever, BaseModel):\n",
        "    \n",
        "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def get_relevant_documents(self, query: str, num_docs=2) -> List[Document]:\n",
        "        initial_docs = self.vectorstore.similarity_search(query, k=30)\n",
        "        return rerank_documents(query, initial_docs, top_n=num_docs)\n",
        "\n",
        "# Create the custom retriever\n",
        "custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
        "\n",
        "# Create an LLM for answering questions\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
        "\n",
        "# Create the RetrievalQA chain with the custom retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=custom_retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/rt/0kf7v29569z7rctzmpst_dsh0000gn/T/ipykernel_58183/546735038.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"query\": query})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question: What are the impacts of climate change on biodiversity?\n",
            "Answer: Climate change impacts biodiversity by altering terrestrial and marine ecosystems. It shifts habitat ranges, changes species distributions, and affects ecosystem functions, leading to potential loss of biodiversity and disruption of ecological balance. In terrestrial ecosystems like forests, grasslands, and deserts, there are shifts in plant and animal species composition. In marine ecosystems, rising sea temperatures, ocean acidification, and changing currents affect marine biodiversity, disrupting marine food webs and fisheries. These changes can lead to species migration and altered reproductive cycles, further impacting biodiversity.\n",
            "\n",
            "Relevant source documents:\n",
            "\n",
            "Document 1:\n",
            "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
            "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
            "experiencing shi...\n",
            "\n",
            "Document 2:\n",
            "protection, and habitat creation. \n",
            "Climate-Resilient Conservation \n",
            "Conservation strategies must account for climate change impacts to be effective. This \n",
            "includes identifying climate refugia, areas le...\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain({\"query\": query})\n",
        "\n",
        "print(f\"\\nQuestion: {query}\")\n",
        "print(f\"Answer: {result['result']}\")\n",
        "print(\"\\nRelevant source documents:\")\n",
        "for i, doc in enumerate(result[\"source_documents\"]):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example that demonstrates why we should use reranking "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison of Retrieval Techniques\n",
            "==================================\n",
            "Query: what is the capital of france?\n",
            "\n",
            "Baseline Retrieval Result:\n",
            "\n",
            "Document 1:\n",
            "The capital of France is great.\n",
            "\n",
            "Document 2:\n",
            "The capital of France is beautiful.\n",
            "\n",
            "Advanced Retrieval Result:\n",
            "\n",
            "Document 1:\n",
            "I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\n",
            "\n",
            "Document 2:\n",
            "Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower. \n",
            "    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\n"
          ]
        }
      ],
      "source": [
        "chunks = [\n",
        "    \"The capital of France is great.\",\n",
        "    \"The capital of France is huge.\",\n",
        "    \"The capital of France is beautiful.\",\n",
        "    \"\"\"Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower. \n",
        "    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\"\"\", \n",
        "    \"I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\"\n",
        "]\n",
        "docs = [Document(page_content=sentence) for sentence in chunks]\n",
        "\n",
        "\n",
        "def compare_rag_techniques(query: str, docs: List[Document] = docs) -> None:\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "    print(\"Comparison of Retrieval Techniques\")\n",
        "    print(\"==================================\")\n",
        "    print(f\"Query: {query}\\n\")\n",
        "    \n",
        "    print(\"Baseline Retrieval Result:\")\n",
        "    baseline_docs = vectorstore.similarity_search(query, k=2)\n",
        "    for i, doc in enumerate(baseline_docs):\n",
        "        print(f\"\\nDocument {i+1}:\")\n",
        "        print(doc.page_content)\n",
        "\n",
        "    print(\"\\nAdvanced Retrieval Result:\")\n",
        "    custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
        "    advanced_docs = custom_retriever.get_relevant_documents(query)\n",
        "    for i, doc in enumerate(advanced_docs):\n",
        "        print(f\"\\nDocument {i+1}:\")\n",
        "        print(doc.page_content)\n",
        "\n",
        "\n",
        "query = \"what is the capital of france?\"\n",
        "compare_rag_techniques(query, docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 2: Cross Encoder models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "\n",
        "<img src=\"../images/rerank_cross_encoder.svg\" alt=\"rerank cross encoder\" style=\"width:40%; height:auto;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the cross encoder class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81bcf5f71afb4dbd9a62557e068785a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "108f6a0a11f243018136dd3a33506757",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c56481fbf75845cb8f38853b6d79e85b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f69f263dc5411fa5bf0a32dfc1ee04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0175a7ff6d17476d974778f94a418430",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4426d229df564f0b965b24fe820d8529",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6362e22344bf4dea8474f42848f0f592",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/rt/0kf7v29569z7rctzmpst_dsh0000gn/T/ipykernel_80757/2986707392.py:3: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  class CrossEncoderRetriever(BaseRetriever, BaseModel):\n",
            "/var/folders/rt/0kf7v29569z7rctzmpst_dsh0000gn/T/ipykernel_80757/2986707392.py:3: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
            "  class CrossEncoderRetriever(BaseRetriever, BaseModel):\n",
            "/var/folders/rt/0kf7v29569z7rctzmpst_dsh0000gn/T/ipykernel_80757/2986707392.py:3: DeprecationWarning: Retrievers must implement abstract `_aget_relevant_documents` method instead of `aget_relevant_documents`\n",
            "  class CrossEncoderRetriever(BaseRetriever, BaseModel):\n"
          ]
        }
      ],
      "source": [
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "# This model specializes in relevance scoring for query-passage pairs, outputting a single logit/score \n",
        "# (higher = more relevant, typically sigmoided to [0,1]).\n",
        "\n",
        "class CrossEncoderRetriever(BaseRetriever, BaseModel):\n",
        "    \"\"\"\n",
        "    Inherits from BaseRetriever (LangChain interface for retrievers) and BaseModel (Pydantic for validation/serialization).\n",
        "    This makes it pluggable into chains like RetrievalQA (e.g., RetrievalQA.from_chain_type(retriever=cross_retriever)).\n",
        "\n",
        "    Args:\n",
        "        BaseRetriever (_type_): _description_\n",
        "        BaseModel (_type_): _description_\n",
        "\n",
        "    Raises:\n",
        "        NotImplementedError: _description_\n",
        "\n",
        "    Returns:\n",
        "        _type_: _description_\n",
        "\n",
        "    Bi-encoders (like your vectorstore embeddings) encode query and docs separately, then compare via dot product \n",
        "    (fast but less precise).\n",
        "    \n",
        "    Cross-encoders encode the query-doc pair jointly (concatenated input), capturing deeper interactions \n",
        "    (e.g., how query words relate to doc words). More accurate but slower (hence used only for reranking small sets).\n",
        "    \"\"\"\n",
        "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
        "    cross_encoder: Any = Field(description=\"Cross-encoder model for reranking\")\n",
        "    k: int = Field(default=5, description=\"Number of documents to retrieve initially\")\n",
        "    rerank_top_k: int = Field(default=3, description=\"Number of documents to return after reranking\")\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        # Initial retrieval\n",
        "        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n",
        "        \n",
        "        # Prepare pairs for cross-encoder\n",
        "        pairs = [[query, doc.page_content] for doc in initial_docs]\n",
        "        # Creates a list of query-document pairs: [[query_str, doc_text1], [query_str, doc_text2], ...] (5 pairs total).\n",
        "        # Each pair is a list of two strings (query first, doc second)—this is the exact format CrossEncoder.predict() expects.\n",
        "        \n",
        "        # Get cross-encoder scores\n",
        "        scores = self.cross_encoder.predict(pairs)\n",
        "        # Feeds all pairs batched to the model: predict() processes them in one go (vectorized inference)\n",
        "    \n",
        "        # Sort documents by score, high to low\n",
        "        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n",
        "        \n",
        "        # Return top reranked documents\n",
        "        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]\n",
        "\n",
        "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
        "        raise NotImplementedError(\"Async retrieval not implemented\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an instance and showcase over an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/rt/0kf7v29569z7rctzmpst_dsh0000gn/T/ipykernel_80757/1913018418.py:22: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"query\": query})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question: What are the impacts of climate change on biodiversity?\n",
            "Answer: Climate change impacts biodiversity by altering terrestrial ecosystems, which includes shifting habitat ranges, changing species distributions, and affecting ecosystem functions. This can lead to a loss of biodiversity and disrupt ecological balance. In marine ecosystems, climate change makes them highly vulnerable due to rising sea temperatures, ocean acidification, and changing currents, which affect marine biodiversity, including coral reefs and deep-sea habitats. Species migration and changes in reproductive cycles can disrupt marine food webs and fisheries. Overall, these changes threaten the stability and health of various ecosystems.\n",
            "\n",
            "Relevant source documents:\n",
            "\n",
            "Document 1:\n",
            "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
            "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
            "experiencing shi...\n",
            "\n",
            "Document 2:\n",
            "protection, and habitat creation. \n",
            "Climate-Resilient Conservation \n",
            "Conservation strategies must account for climate change impacts to be effective. This \n",
            "includes identifying climate refugia, areas le...\n",
            "\n",
            "Document 3:\n",
            "goals. Policies should promote synergies between biodiversity conservation and climate \n",
            "action. \n",
            "Chapter 10: Climate Change and Human Health \n",
            "Health Impacts \n",
            "Heat-Related Illnesses \n",
            "Rising temperature...\n",
            "\n",
            "Document 4:\n",
            "Local communities are often on the front lines of climate impacts and can be powerful agents \n",
            "of change. Community-based conservation projects involve residents in protecting and \n",
            "restoring natural re...\n",
            "\n",
            "Document 5:\n",
            "cultural perceptions. \n",
            "Youth Engagement \n",
            "Youth are vital stakeholders in climate action. Empowering young people through education, \n",
            "activism, and leadership opportunities can drive transformative cha...\n"
          ]
        }
      ],
      "source": [
        "# Create the cross-encoder retriever\n",
        "cross_encoder_retriever = CrossEncoderRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    cross_encoder=cross_encoder,\n",
        "    k=10,  # Retrieve 10 documents initially\n",
        "    rerank_top_k=5  # Return top 5 after reranking\n",
        ")\n",
        "\n",
        "# Set up the LLM\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
        "\n",
        "# Create the RetrievalQA chain with the cross-encoder retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=cross_encoder_retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# Example query\n",
        "query = \"What are the impacts of climate change on biodiversity?\"\n",
        "result = qa_chain({\"query\": query})\n",
        "\n",
        "print(f\"\\nQuestion: {query}\")\n",
        "print(f\"Answer: {result['result']}\")\n",
        "print(\"\\nRelevant source documents:\")\n",
        "for i, doc in enumerate(result[\"source_documents\"]):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['query', 'result', 'source_documents'])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://europe-west1-rag-techniques-views-tracker.cloudfunctions.net/rag-techniques-tracker?notebook=all-rag-techniques--reranking)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "agentenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
