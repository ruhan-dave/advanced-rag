{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c47b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root to path: /Users/ruhwang/Desktop/AI/my_projects/context-engineering/advanced-rag\n",
      "✅ Package imported successfully!\n",
      "LANGCHAIN_API_KEY not set (empty in .env file)\n",
      "Environment setup complete!\n",
      "=== API Keys from config.py ===\n",
      "  GROQ_API_KEY: Loaded\n",
      "  COHERE_API_KEY: Loaded\n",
      "  OPENAI_API_KEY: Loaded\n",
      "  LANGCHAIN_API_KEY: Missing\n",
      "\n",
      "=== Environment Variables ===\n",
      "  os.environ['GROQ_API_KEY']: Set\n",
      "  os.environ['COHERE_API_KEY']: Set\n",
      "\n",
      "All essential keys loaded!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Define the directory *containing* the all_rag_techniques package\n",
    "# Get the directory of the current notebook/script (__file__ might not work in some notebooks)\n",
    "# Assuming the notebook is inside all_rag_techniques/\n",
    "current_dir = Path.cwd() \n",
    "\n",
    "# The directory containing 'all_rag_techniques' is the parent directory\n",
    "project_root = current_dir.parent \n",
    "\n",
    "# 2. Add this root to the system path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(f\"Added project root to path: {project_root}\")\n",
    "else:\n",
    "    print(\"Project root already in path.\")\n",
    "\n",
    "# 3. Now the import should work\n",
    "try:\n",
    "    from all_rag_techniques import setup_environment, check_keys\n",
    "    print(\"✅ Package imported successfully!\")\n",
    "    setup_environment()\n",
    "    check_keys()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Final import failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef1fe3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, SVMRetriever, TFIDFRetriever, EmbedchainRetriever, MultiQueryRetriever\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ef64ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Tuple\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af9848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=512)\n",
    "path = \"/Users/ruhwang/Desktop/AI/my_projects/context-engineering/advanced-rag/data/Understanding_Climate_Change.pdf\"\n",
    "vectorstore = encode_pdf(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd36b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingScore(BaseModel):\n",
    "    relevance_score: float = Field(..., description=\"The relevance score of a document to a query.\")\n",
    "\n",
    "def rerank_documents(query: str, docs: List[Document], top_n: int = 3) -> List[Document]:\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"query\", \"doc\"],\n",
    "        template=\"\"\"On a scale of 1-10, rate the relevance of the following document to the query. \n",
    "        Consider the specific context and intent of the query, not just keyword matches.\n",
    "        Query: {query}\n",
    "        Document: {doc}\n",
    "        Relevance Score:\"\"\"\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=0.25, model_name=\"gpt-4o-mini\", max_tokens=4000)\n",
    "    llm_chain = prompt_template | llm.with_structured_output(RatingScore)\n",
    "    \n",
    "    scored_docs = []\n",
    "    for doc in docs:\n",
    "        input_data = {\"query\": query, \"doc\": doc.page_content}\n",
    "        score = llm_chain.invoke(input_data).relevance_score\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except ValueError:\n",
    "            score = 0  # Default score if parsing fails\n",
    "        scored_docs.append((doc, score))\n",
    "    \n",
    "    reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, _ in reranked_docs[:top_n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc041007",
   "metadata": {},
   "source": [
    "BM25Retriever must be initialized with the documents it needs to search over. Unlike a vector store that you might pass in, a BM25Retriever is typically built from a collection of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3901c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "chunk_overlap = 20\n",
    "\n",
    "# Load PDF and create documents\n",
    "loader = PyPDFLoader(path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)\n",
    "cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=512)\n",
    "vectorstore = FAISS.from_documents(cleaned_texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d63db41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Instantiate the BM25Retriever using the class method 'from_documents'\n",
    "bm25_retriever = BM25Retriever.from_documents(documents=documents)\n",
    "svm_retriever = SVMRetriever.from_documents(\n",
    "    documents=documents,\n",
    "    embeddings=embeddings \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c208110",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_retriever = TFIDFRetriever.from_documents(\n",
    "    documents=documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80aa0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same LLM you're using for your QA chain (or a faster one)\n",
    "llm_for_query_gen = ChatOpenAI(temperature=0.2, model_name=\"gpt-4o-mini\") \n",
    "\n",
    "# Use vector store retriever as the base\n",
    "base_retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 2. Create the Multi-Query Retriever\n",
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=base_retriever,\n",
    "    llm=llm_for_query_gen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2498f84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rt/0kf7v29569z7rctzmpst_dsh0000gn/T/ipykernel_14539/2125800789.py:2: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
      "  class CustomEnsembleRetriever(BaseRetriever, BaseModel):\n"
     ]
    }
   ],
   "source": [
    "# Create a custom retriever class\n",
    "class CustomEnsembleRetriever(BaseRetriever, BaseModel):\n",
    "    \n",
    "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
    "    retrievers: List[BaseRetriever] = Field(description=\"List of retrievers to ensemble\")\n",
    "    weights: List[float] = Field(description=\"Weights for each retriever in the ensemble\")\n",
    "\n",
    "    def get_relevant_documents(self, query: str, num_docs=2) -> List[Document]:\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=30)\n",
    "        return rerank_documents(query, initial_docs, top_n=num_docs)\n",
    "\n",
    "# Create the custom retriever\n",
    "ensemble_retriever = CustomEnsembleRetriever(vectorstore=vectorstore,\n",
    "                                             retrievers=[bm25_retriever, svm_retriever, tfidf_retriever, multiquery_retriever],\n",
    "                                             weights=[0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "# Create an LLM for answering questions\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# Create the RetrievalQA chain with the custom retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=ensemble_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09607b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rt/0kf7v29569z7rctzmpst_dsh0000gn/T/ipykernel_14539/3233511906.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: How does climate change affect marine ecosystems?\n",
      "Answer: Climate change affects marine ecosystems in several ways, including rising sea temperatures, ocean acidification, and changing currents. These changes can impact marine biodiversity, affecting everything from coral reefs to deep-sea fisheries. For example, ocean acidification disrupts the health and survival of various marine species, which in turn can disrupt food webs. Protecting and restoring coral reefs is essential for marine conservation in the face of these challenges.\n",
      "\n",
      "Relevant source documents:\n",
      "\n",
      "Document 1:\n",
      "Marine Ecosystems \n",
      "Marine ecosystems are highly vulnerable to climate change. Rising sea temperatures, ocean \n",
      "acidification, and changing currents affect marine biodiversity, from coral reefs to deep-...\n",
      "\n",
      "Document 2:\n",
      "fisheries. Protecting and restoring coral reefs is essential for marine conservation. \n",
      "Marine Ecosystems \n",
      "Acidification affects the health and survival of various marine species, disrupting food webs...\n"
     ]
    }
   ],
   "source": [
    "query = \"How does climate change affect marine ecosystems?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\nQuestion: {query}\")\n",
    "print(f\"Answer: {result['result']}\")\n",
    "print(\"\\nRelevant source documents:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c1c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
